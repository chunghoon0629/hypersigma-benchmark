# Target Detection (타겟 탐지) - AVIRIS 데이터셋

## 1차 검증: 논문 기반

### 논문 요약

HyperSIGMA 논문에서 Target Detection 태스크는 **Test-time Adaptation** 방식으로 진행된다.
테스트 이미지 자체에서 Pseudo-label을 생성하여 모델을 적응시킨 후 평가한다.

#### Pseudo-label 생성 (Coarse Detection)
- **알고리즘**: CEM (Constrained Energy Minimization)
- **타겟 라벨링**: 상위 **1.5%** 픽셀
- **배경 라벨링**: 하위 **30%** 픽셀
- **나머지**: 손실 계산 시 무시

#### 입력 구성
- **패치 크기**: 32×32
- **패치 중복**: 16 픽셀

#### 학습 설정
| 항목 | 값 |
|------|-----|
| 에포크 | 10 |
| 배치 사이즈 | 2 |
| 학습률 | 6e-5 |
| 옵티마이저 | AdamW |
| 스펙트럼 토큰 수 | 100 |
| 손실 함수 | Cross-Entropy |

#### 인코더 설정
- 패치 임베딩 레이어: 무작위 초기화 후 재학습
- 전체 네트워크 미세 조정


---

## 2차 검증: 원저자 코드 기반

**원저자 코드 경로**: `~/gsjo/paper/HyperSIGMA/HyperspectralDetection/Target_Detection/`

### 중요 발견: 논문 vs 원저자 코드 차이

| 항목 | 논문 | 원저자 코드 |
|------|------|-------------|
| 타겟 라벨링 | 상위 1.5% | 상위 **0.15%** |

### 원저자 코드 분석 결과

#### Pseudo-label 생성
| 항목 | 원저자 코드 | 비고 |
|------|-------------|------|
| 알고리즘 | RX/CEM 기반 탐지 맵 | 사전 계산된 coarse_det 사용 |
| 타겟 라벨링 | 상위 0.15% | `all_idxs[-int(0.0015*r*c):]` |
| 배경 라벨링 | 하위 30% | `all_idxs[:int(0.3*r*c)]` |
| 무시 라벨 | 255 | 나머지 69.85% 픽셀 |

#### 입력 설정
| 항목 | 원저자 코드 |
|------|-------------|
| 패치 크기 | 32×32 |
| 패치 중복 | 16 |
| Step Size | 16 (= 32 - 16) |

#### 학습 설정
| 항목 | 원저자 코드 |
|------|-------------|
| 에포크 | 10 |
| 배치 사이즈 | 2 |
| 학습률 | 6e-5 |
| Weight Decay | 5e-4 |
| 옵티마이저 | AdamW (betas=0.9, 0.999) |
| Layer Decay Rate | 0.9 |
| Scheduler | CosineAnnealingLR (eta_min=0) |
| 손실 함수 | CrossEntropyLoss (ignore_index=255) |

#### 정규화 및 기타
| 항목 | 원저자 코드 |
|------|-------------|
| 입력 정규화 | StandardScaler |
| 출력 정규화 | Min-Max [0, 1] |
| Target Spectrum | 타겟 픽셀의 평균 스펙트럼 |


---

## 검증 결과 종합 (업데이트: 코드 수정 후)

### i) 논문/원저자와 일치하는 것 ✅

| 항목 | 논문 | 원저자 | 현재 구현 | 상태 |
|------|------|--------|-----------|------|
| **Pseudo-label 생성** | CEM | RX/CEM | RX 기반 | ✅ |
| **타겟 라벨링** | 상위 1.5% | 상위 0.15% | **0.15%** | ✅ |
| **배경 라벨링** | 하위 30% | 하위 30% | **30%** | ✅ |
| **패치 크기** | 32×32 | 32×32 | **32** | ✅ |
| **패치 중복** | 16 | 16 | **16** | ✅ |
| **에포크** | 10 | 10 | **10** | ✅ |
| **배치 사이즈** | 2 | 2 | **2** | ✅ |
| **학습률** | 6e-5 | 6e-5 | **6e-5** | ✅ |
| **스펙트럼 토큰 수** | 100 | 100 | **100** | ✅ |
| **옵티마이저** | AdamW | AdamW | AdamW | ✅ |
| **Weight Decay** | - | 5e-4 | **5e-4** | ✅ |
| **Layer Decay** | - | 0.9 | **0.9** | ✅ |
| **Scheduler eta_min** | - | 0 | **0** | ✅ |
| **정규화** | - | StandardScaler | **StandardScaler** | ✅ |
| **무시 라벨 처리** | - | ignore_index=255 | mask 기반 | ✅ |

### ii) 구현 방식 차이 (기능적 동등) ⚠️

| 항목 | 원저자 | 현재 구현 | 비고 |
|------|--------|-----------|------|
| 손실 함수 | CrossEntropyLoss (ignore_index=255) | BCEWithLogitsLoss + mask | 동일 효과 |

### iii) 이전 버전 대비 수정된 항목

| 항목 | 이전 구현 | 현재 구현 |
|------|-----------|-----------|
| Pseudo-label 생성 | 미구현 | RX 기반 ✅ |
| 타겟 라벨링 | 직접 라벨 | 상위 0.15% ✅ |
| 배경 라벨링 | 1:5 샘플링 | 하위 30% ✅ |
| 패치 크기 | 7×7 | 32×32 ✅ |
| 패치 중복 | 없음 | 16 ✅ |
| 에포크 | 50 | 10 ✅ |
| 배치 사이즈 | 32 | 2 ✅ |
| 학습률 | 1e-4 | 6e-5 ✅ |
| Weight Decay | 0.01 | 5e-4 ✅ |
| Layer Decay | 미적용 | 0.9 ✅ |
| 정규화 | Min-Max | StandardScaler ✅ |


---

## 최종 결론

| 구분 | 개수 | 상태 |
|------|------|------|
| **논문/원저자 일치** | 15개 | ✅ |
| **기능적 동등** | 1개 | ⚠️ |
| **불일치** | 0개 | - |

**Target Detection 태스크 검증 완료** ✅

