# Unmixing (언믹싱) - Urban4 데이터셋

## 1차 검증: 논문 기반

### 논문 요약

HyperSIGMA 논문에서 Unmixing 태스크는 **Unsupervised/Self-supervised 재구성 기반** 학습을 사용한다.

#### 학습 방식
- 입력 이미지(X)를 인코더-디코더로 복원(X̂)하는 과정에서 손실 최소화
- 네트워크 가중치(W_D) → Endmember로 해석
- 잠재 특징(Z) → Abundance로 해석

#### 입력 구성
- **패치 크기**: 64×64

#### 학습 설정
| 항목 | 값 |
|------|-----|
| 에포크 | 200 |
| 배치 사이즈 | 32 |
| Spatial ViT patch size | 2 |
| 스펙트럼 토큰 수 | 64 |
| Sparsity 손실 가중치 (α) | 0.35 |
| TV 손실 가중치 (β) | 0.1 |
| 학습률 | (명시 안됨) |

#### 인코더 설정
- 공간 브랜치: 4개 특징 맵 (F1, F2, F3, F4) 사용
- 분광 브랜치: 마지막 특징(V) 사용
- 세밀한 공간 정보 유지를 위해 Spatial ViT patch size = 2


---

## 2차 검증: 원저자 코드 기반

**원저자 코드 경로**: `~/gsjo/paper/HyperSIGMA/HyperspectralUnmixing/`

### 원저자 코드 분석 결과

#### 학습 설정
| 항목 | 원저자 코드 |
|------|-------------|
| 입력 패치 크기 | 64×64 |
| 에포크 | 200 |
| 배치 사이즈 | 32 |
| Spatial ViT patch size | 2 |
| 스펙트럼 토큰 수 | 64 |
| 학습률 | 0.001 |
| Weight Decay | 0.05 |
| Layer Decay Rate | 0.9 |
| Scheduler | CosineAnnealingLR (eta_min=0) |
| 옵티마이저 | AdamW (betas=0.9, 0.999) |

#### 손실 함수
```
Loss = SAD_loss + α × √(Abundance) + β × TV(Endmember)

- SAD_loss: Spectral Angle Distance (재구성 손실)
- α = 0.35 (희소성 정규화)
- β = 0.1 (Total Variation 정규화)
```

#### 기타 설정
| 항목 | 원저자 코드 |
|------|-------------|
| Endmember 초기화 | VCA (Vertex Component Analysis) |
| 데이터 증강 | RandomHorizontalFlip, RandomVerticalFlip |
| ViT 깊이 | 12 |
| ViT 헤드 | 12 |
| Embed Dim | 768 |


---

## 검증 결과 종합

### i) 논문에 있는데 다른 것 ❌

| 항목 | 논문 | 원저자 | 현재 구현 |
|------|------|--------|-----------|
| **입력 패치 크기** | 64×64 | 64×64 | **7×7** ❌ |
| **에포크** | 200 | 200 | **50** ❌ |
| **배치 사이즈** | 32 | 32 | **64** ❌ |
| **Spatial ViT patch size** | 2 | 2 | **1** ❌ |
| **스펙트럼 토큰 수** | 64 | 64 | **100** ❌ |
| **Sparsity 손실 (α=0.35)** | ✅ | ✅ | **미구현** ❌ |
| **TV 손실 (β=0.1)** | ✅ | ✅ | **미구현** ❌ |

### ii) 논문에 언급되지 않은 디테일 (원저자 코드로 확인)

| 항목 | 원저자 코드 | 현재 구현 | 일치 |
|------|-------------|-----------|------|
| 학습률 | 0.001 | 1e-4 | ❌ |
| Weight Decay | 0.05 | 0.01 | ❌ |
| Scheduler eta_min | 0 | 1e-6 | ❌ |
| Layer Decay | 0.9 | 미적용 | ❌ |
| Endmember 초기화 | VCA | 미확인 | ? |
| 데이터 증강 | Flip | 미확인 | ? |
| 재구성 손실 | SAD | SAD | ✅ |

### iii) 논문과 일치하는 것 ✅

| 항목 | 논문 | 원저자 | 현재 구현 |
|------|------|--------|-----------|
| 데이터셋 | Urban4 | Urban4 | Urban4 ✅ |
| 학습 방식 | 재구성 기반 | 재구성 기반 | 재구성 기반 ✅ |


---

## 최종 결론

| 구분 | 개수 | 상태 |
|------|------|------|
| **논문과 일치** | 2개 | ✅ |
| **논문과 불일치** | 7개 | ❌ |
| **원저자와 불일치** | 4개+ | ❌ |

### 수정 필요 사항 (우선순위 순)

1. **입력 패치 크기**: 7 → **64**
2. **에포크**: 50 → **200**
3. **배치 사이즈**: 64 → **32**
4. **Spatial ViT patch size**: 1 → **2**
5. **스펙트럼 토큰 수**: 100 → **64**
6. **Sparsity 손실 구현**: `α × √(Abundance).mean()` (α=0.35)
7. **TV 손실 구현**: `β × |E[:,1:] - E[:,:-1]|.sum()` (β=0.1)
8. **학습률**: 1e-4 → **0.001**
9. **Weight Decay**: 0.01 → **0.05**
10. **Layer Decay 적용**: rate=0.9
11. **Endmember 초기화**: VCA 사용
12. **데이터 증강**: RandomFlip 추가

**Unmixing 태스크는 전반적인 재구현이 필요함**
