# HyperSIGMA Benchmark

Reproducible benchmark suite for [HyperSIGMA](https://github.com/WHU-Sigma/HyperSIGMA) - Hyperspectral Intelligence Comprehension Foundation Model.

This repository provides clean, unified implementations for running HyperSIGMA on standard hyperspectral imaging benchmarks.

## Quick Start

### 1. Clone and Setup

```bash
git clone <this-repo>
cd hypersigma-benchmark

# Install dependencies
pip install -r requirements.txt
```

### 2. Download Pretrained Weights

```bash
bash scripts/download_weights.sh
```

Or manually download from [HuggingFace](https://huggingface.co/WHU-Sigma/HyperSIGMA):
- `spat-vit-base-ultra-checkpoint-1599.pth`
- `spec-vit-base-ultra-checkpoint-1599.pth`

Place weights in `pretrained/` directory.

### 3. Prepare Data

Place datasets in the `data/` directory following this structure:

```
data/
â”œâ”€â”€ anomaly_detection/
â”‚   â”œâ”€â”€ Pavia_150_150_102.mat
â”‚   â”œâ”€â”€ Pavia_coarse_det_map.mat
â”‚   â””â”€â”€ ...
â”œâ”€â”€ classification/
â”‚   â”œâ”€â”€ Indian_pines_corrected.mat
â”‚   â”œâ”€â”€ Indian_pines_gt.mat
â”‚   â”œâ”€â”€ PaviaU.mat
â”‚   â”œâ”€â”€ PaviaU_gt.mat
â”‚   â””â”€â”€ ...
â””â”€â”€ ...
```

### 4. Run Benchmarks

```bash
# Anomaly Detection
python tasks/anomaly_detection/train.py --dataset pavia --mode ss --epochs 10

# Classification
python tasks/classification/train.py --dataset indian_pines --samples_per_class 10

# Or use unified runner
python scripts/run_benchmark.py --task anomaly --dataset pavia --mode ss
python scripts/run_benchmark.py --task classification --dataset indian_pines --samples 10
```

## Available Tasks

| Task | Status | Datasets |
|------|--------|----------|
| Anomaly Detection | âœ… Ready | Pavia, CRI |
| Classification | âœ… Ready | Indian Pines, PaviaU, Houston |
| Change Detection | ðŸ”² Planned | Bay Area |
| Denoising | ðŸ”² Planned | WDC |
| Unmixing | ðŸ”² Planned | Urban4 |

## Results

### Anomaly Detection (Pavia)

| Mode | AUC-ROC |
|------|---------|
| sa (spatial-only) | ~86.17% |
| ss (spectral-spatial) | ~84.45% |

### Classification

Results with 10 samples per class:

| Dataset | OA | AA | Kappa |
|---------|----|----|-------|
| Indian Pines | TBD | TBD | TBD |
| PaviaU | TBD | TBD | TBD |

## Repository Structure

```
hypersigma-benchmark/
â”œâ”€â”€ README.md                    # This file
â”œâ”€â”€ requirements.txt             # Dependencies
â”œâ”€â”€ RESULTS.md                   # Auto-generated results
â”‚
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ paths.yaml               # Path configuration
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ download_weights.sh      # Download pretrained weights
â”‚   â”œâ”€â”€ run_benchmark.py         # Unified benchmark runner
â”‚   â””â”€â”€ collect_results.py       # Aggregate results
â”‚
â”œâ”€â”€ pretrained/                  # Weights (gitignored)
â”‚   â”œâ”€â”€ spat-vit-base-ultra-checkpoint-1599.pth
â”‚   â””â”€â”€ spec-vit-base-ultra-checkpoint-1599.pth
â”‚
â”œâ”€â”€ hypersigma/                  # Core model code
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ spat_vit.py          # Spatial ViT encoder
â”‚   â”‚   â”œâ”€â”€ spec_vit.py          # Spectral ViT encoder
â”‚   â”‚   â””â”€â”€ task_heads.py        # Task-specific heads
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ checkpoint.py        # Weight loading
â”‚   â”‚   â”œâ”€â”€ metrics.py           # Evaluation metrics
â”‚   â”‚   â””â”€â”€ data_utils.py        # Data utilities
â”‚   â””â”€â”€ mmcv_custom/             # Optimizer constructors
â”‚
â”œâ”€â”€ tasks/
â”‚   â”œâ”€â”€ anomaly_detection/
â”‚   â”‚   â”œâ”€â”€ train.py
â”‚   â”‚   â”œâ”€â”€ config.py
â”‚   â”‚   â””â”€â”€ README.md
â”‚   â”œâ”€â”€ classification/
â”‚   â”‚   â”œâ”€â”€ train.py
â”‚   â”‚   â”œâ”€â”€ config.py
â”‚   â”‚   â””â”€â”€ README.md
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ data/                        # Datasets (gitignored)
â””â”€â”€ results/                     # Outputs (gitignored)
```

## Model Architecture

HyperSIGMA uses a dual-encoder architecture:

- **SpatViT**: Spatial Vision Transformer for spatial feature extraction
- **SpecViT**: Spectral Vision Transformer for spectral feature extraction

Both encoders are pretrained on large-scale hyperspectral data and can be used independently or together.

## Citation

If you use this benchmark, please cite the original HyperSIGMA paper:

```bibtex
@article{hypersigma2024,
  title={HyperSIGMA: Hyperspectral Intelligence Comprehension Foundation Model},
  author={...},
  journal={...},
  year={2024}
}
```

## License

This benchmark code is released under MIT License. The HyperSIGMA model weights are subject to their original license.

## Acknowledgments

- Original HyperSIGMA: [WHU-Sigma/HyperSIGMA](https://github.com/WHU-Sigma/HyperSIGMA)
- This benchmark is created for fair comparison with [SpectralFM](https://github.com/...)
